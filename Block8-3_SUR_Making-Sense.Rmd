---
title: "Asking Questions from Survey Data"
pagetitle: "Asking Questions from Survey Data"
output:
  html_document:
    code_folding: show # allows toggling of showing and hiding code. Remove if not using code.
    code_download: true # allows the user to download the source .Rmd file. Remove if not using code.
    includes:
      after_body: footer.html # include a custom footer.
    toc: true
    toc_depth: 3
    toc_float:
      collapsed: false
      smooth_scroll: false
---
```{r setup, include=FALSE}
knitr::opts_chunk$set(message = FALSE, warnings = FALSE)
```

## Asking Questions from Survey Data

Now that we have cleaned up our survey data, we can start asking questions about it! By the end of the previous session, <a href="Block8-2_SUR_Collect-and_clean.html">Collecting and Cleaning Survey Data</a>, we generated two cleaned datasets:

* `survey_data_tidy.csv`
* `survey-data_wide.csv`

Long, or "tidy" data and wide data each have their pros and cons, and in this session we're going to explore the benefits and drawbacks of each as we explore our data. But first, let's take a moment to do some thinking:

To begin, let's open up our `.RProj` file, so that our working directory will be captured. Now, let's create a new R script, and call it `survey_analysis_script.R`. 

### Load the Tidyverse

Now that we've started a new script, we need to load the libraries that we'll be using, which in this case is just the Tidyverse.

```{r, eval=TRUE, include=FALSE}
library(tidyverse)
```

```{r, eval=FALSE}
library(tidyverse)
```

### Load the data

We can now load the two datasets that were generated in the previous session:

```{r, eval=TRUE, include=FALSE}
survey_data_tidy <- read_csv("data/survey-cleaning-workshop/survey_data_tidy.csv")
```

```{r, eval=TRUE, include=FALSE}
survey_data_wide <- read_csv("data/survey-cleaning-workshop/survey_data_wide.csv")
```

```{r, eval=FALSE}
survey_data_tidy <- read_csv("survey_data_tidy.csv")
```

```{r, eval=FALSE}
survey_data_wide <- read_csv("survey_data_wide.csv")
```


:::question

1) Take a look at `survey_data_tidy` and `survey-data_wide` using the `View()` command. 
```{r, class.source = 'fold-hide', eval = FALSE}
View(survey_data_tidy)
View(survey_data_wide)
```
2) In groups, spend a few minutes talking about some things you'd like to know about the data (ie. groups you'd like to count, possible relationships, etc.).

3) Taking a closer look at the `tidy` and `wide` datasets, can you think of reasons why certain questions might be better with either one of the datasets?

:::

## Exploring Wide Data

Wide data is easier for humans to read and interpret, and lends itself well to asking simple questions from single variables, or columns, of data. Tidy data is better for asking more complicated questions, as well as asking about multiple variables and possible relationships between them. Let's first start with some simple questions we can ask from the **wide version** of our data.

A simple first step when exploring a dataset is getting counts of individual variables. To do this, we can use the `count()` function:

:::walkthrough

**What does the sample breadkdown of gender?**
```{r, eval=FALSE}
survey_data_wide |>
  count(gender)
```

**Step-by-step explanation:**

1) We start with the `survey_data_wide` object and use the pipe, `|>`, to indicate we want to do something with it.
2) We then use the `count()` function to give us a total sum of whatever variable/column name we put inside the brackets.
:::

**What is the sample breakdown of age?**
```{r, eval=FALSE}
survey_data_wide |>
  count(age)
```

In addition to looking at single variables with the `count()` function, we can also generate quick summary tables across multiple variables by separating them with commas `,`:

**What is the sample breakdown of age and gender?**
```{r, eval=TRUE}
survey_data_wide |>
  count(age, gender)
```

You'll see the note that there are 14 more rows, and that you can use the `print()` function to view more. You can do this you can do this by specifiying the amount of rows (in this case there are 24)
```{r, eval=FALSE}
survey_data_wide |>
  count(age, gender) |>
  print(n = 24)
```

You can keep adding additional variables to these, noting that each variable will add additional rows. If you don't want to look at the values in the R console, you can use the `View()` function to open it in a separate tab.
```{r, eval=FALSE}
survey_data_wide |>
  count(age, gender, year_of_study) |>
  View()
```

If this is something you want to come back to, you can save it into an R object.
```{r, eval=FALSE}
demographics_count <- survey_data_wide |>
  count(age, gender, year_of_study)

View(demographics_count)
```

A final thing that can be helpful with the `count()` function is adding in the proportion that each sum represents in the total sample.

:::walkthrough
```{r, eval=FALSE}
survey_data_wide |>
  count(gender) |>
  mutate(prop = n / sum(n))
```

**Step-by-step explanation:**

1) Start by piping the `survey_wide` object to the `count()` function like we've been doing.
2) Add another pipe to indicate we are passing that count to another function.
3) `mutate(prop` creates a new column called `prop`, which stands for proportion (you can name this whatever you want).
4) Everything on the right side of the `=` is assigned to the new `prop` column. 
5) `n` is the count for each gender category, and `sum(n)` is the total number of every row/person in the sample.
6) `n / sum(n))` calculates `"count of each category" / "total count"`, which gives a proportion.

:::

## Your Turn!

:::question
See if you can create the following from the `survey_data_wide` object:

1) A count of each `gender` category.
```{r, class.source = 'fold-hide', eval=FALSE}
survey_data_wide |>
  count(gender)
```
2) A count of each `age` and `year_of_study`.
```{r, class.source = 'fold-hide', eval=FALSE}
survey_data_wide |>
  count(age, year_of_study)
```
3) The count of `age` and its proportion.
```{r, class.source = 'fold-hide', eval=FALSE}
survey_data_wide |>
  count(age) |>
  mutate(prop = n / sum(n))
```
4) The count of `age`, `year_of_study`, and the proportion
```{r, class.source = 'fold-hide', eval=FALSE}
survey_data_wide |>
  count(age, year_of_study) |>
  mutate(prop = n / sum(n))
```
:::

## Simple Barplots as Exploration

In addition to creating summary tables to explore data, creating simple plots can be another way to explore your data.

One way to do this, is using the base R `barplot()` function. This can be done in a few steps.


In this example, we're going to plot the categories of the `hours_per_day` columns.

First, let's look at the `$` operator. When placed after a data object in R, it allows you to isolate specified columns.

```{r, eval=FALSE}
survey_data_wide$hours_per_day
```

This will show all the values in that column in the R console. Give it a try with other columns!

Next, we can also use the `table` function here, to generate a quick summary table of that column.

```{r, eval=FALSE}
table(survey_data_wide$hours_per_day)
```

Give this a try with some other columns!

Now we're going to save this table as an object called `hours_table`.

```{r, eval=TRUE}
hours_table <- table(survey_data_wide$hours_per_day)
```

Finally, we can feed the `hours_table` object into the `barplot()` function to get our plot.

```{r, eval=TRUE}
barplot(hours_table)
```

You might notice that the bars aren't in any particular order, which can be a bit annoying. Let's clean this up by creating adding another step. 

```{r, eval=TRUE}
hours_sorted <- sort(hours_table, decreasing = TRUE)
```

```{r, eval=TRUE}
barplot(hours_sorted)
```

The `sort` function is telling R that we want to reorder the values in `hours_table`, and the `decreasing = TRUE` allows us to see the values from biggest to smallest. You can change this to `decreasing = FALSE` to see smallest to biggest.

When exploring data, it's not always necessary to add labels to our plots. However, this chart might be something you want to communicate, so let's add some labels!

```{r, eval=TRUE}
barplot(hours_sorted,
        main = "Hours per day on social media",
        xlab = "Hours per day",
        ylab = "Number of students")
```

With the `barplot()` function:

* `main` is the title of the chart.
* `xlab` is the label on the x (horizontal) axis.
* `ylad` is the label on the y (vertical) axis.

## Your Turn!

:::question

1) Make a barplot for the `feel_increase_stress` variable, that orders the bars from biggest to smallest, and has labels for the title, and both axes.

Hint: break this into 3 steps:

* Create an object that creates a table of the `feel_increase_stress` column
* Create another object that sorts the table in decreasing order
* Create a barplot and add 3 layers of labels.

```{r, class.source = 'fold-hide', eval=FALSE}
stress_count <- table(survey_data_wide$feel_increase_stress)

stress_sorted <- sort(stress_count, decreasing = TRUE)

barplot(stress_sorted,
        main = "Social media makes me feel anxious or stressed",
        xlab = "Feeling anxious or stressed",
        ylab = "Number of students")
```

2) Try this with another column!

:::


## Moving to Tidy Data

As we've seen, working with wide data can be helpful for generating quick summaries and counts. But what if we want to ask something that's a bit more complicated?

:::question

In groups, take a look at the data and talk about how you might go about answering the question, **which platforms are most used?**

:::

There are certainly ways to do this with the wide data. One way would be to use the `count()` function for each individual column. However, this is a bit clunky, and then you would have to then deal with merging the responses into a table (not impossible, but it's more work). There is a way to do this is a single code chunk, but it becomes overly long and complicated:

```{r, eval=FALSE}
platform_counts_wide <- survey_wide |>
  summarise(
    across(
      c(`LinkedIn`, Instagram, Reddit, Facebook,
        `X (Twitter)`, TikTok, Snapchat),
      ~ sum(.x)
    )
  ) |>
  pivot_longer(
    cols = everything(),
    names_to = "platform",
    values_to = "n_users"
  ) |>
  arrange(desc(n_users))

platform_counts_wide
```

We don't need to understand this code chunk, it is just an example of what the code looks like. However, if we shift to **tidy** data, the code becomes much shorter and simpler.

First, let's start by taking another look at the tidy data.

```{r, eval=FALSE}
View(survey_data_tidy)
```

You can see that there is the single `platforms` column that we are able to query.

Now, let's do a count of the different categories in this column.

```{r, eval=TRUE}
survey_data_tidy |>
  count(platforms, name = "n_students")
```

In this code, we are using the `count()` function like we just did, and the `name = "n_students"` creates a new column name for the number for each column. `"n_students"` was used to show this is the number of students, but you can put anything you want here, or leave it blank if preferred.

You can see that this code is very simple, but there is a big problem with the numbers! Because our tidy data adds additional rows to data, we are seeing numbers in the thousands when our sample size is only 300. However, when we cleaned the data, we created a unique ID for each entry. This was to help with re-identifying responses if needed, but it can also help us with eliminating redundant rows.

```{r, eval=TRUE}
survey_data_tidy |>
  distinct(ID, platforms) |>
  count(platforms, name = "n_students")
```

The `distinct()` function is telling R that we only want to keep unique combinations of each student `ID` and `platform`, which eliminates any of the redundancy of the tidy data. As you can see, the numbers are now accurate to our sample.

As with before, it can be nice to arrange the numbers from biggest to smallest.

```{r, eval=TRUE}
survey_data_tidy |>
  distinct(ID, platforms) |>
  count(platforms, name = "n_students") |>
  arrange(desc(n_students))
```

In this case, the `arrange()` function tells R that we want to change the order of something, and `desc(n_students)` specifies that we want the `n_students` column, which is the values for each platform, to be listed in descending order (biggest to smallest).

Finally, once we're happy with the output of this code chunk, we can save it as an R object to revisit. We'll call the object `platform_count`, and now we can easily view and work with it going forward.

```{r, eval=TRUE}
platform_count <- survey_data_tidy |>
  distinct(ID, platforms) |>
  count(platforms, name = "n_students") |>
  arrange(desc(n_students))
```

## Going Deeper with Tidy Data

Let's keep digging into the tidy data, and start asking questions that are related to our bigger research question, **"How does social media usage influence the mental health of university students?**

### **Comparison Operators**

Comparison operators allow us to look for specific criteria in our dataset. These return `TRUE` or `FALSE` based on whether the condition is met.

| Operator | Meaning                  | Example  | Result |
|----------|--------------------------|----------|--------|
| `==`     | Equal to                 | `5 == 5` | `TRUE` |
| `!=`     | Not equal to             | `5 != 3` | `TRUE` |
| `<`      | Less than                | `3 < 5`  | `TRUE` |
| `>`      | Greater than             | `5 > 3`  | `TRUE` |
| `<=`     | Less than or equal to    | `3 <= 3` | `TRUE` |
| `>=`     | Greater than or equal to | `5 >= 3` | `TRUE` |

Once we understand these basic comparison operators, we can combine them using logical operators to create more complex filtering conditions.

### **Logical Operators**

Logical operators allow us to filter data based on multiple conditions.

| Operator | Meaning                                          | Example             | Result  |
|----------|---------------------------------|--------------|-------------|
| `&`      | Logical AND (Both conditions must be TRUE)       | `(5 > 3) & (4 < 6)` | `TRUE`  |
| `|`      | Logical OR (At least one condition must be TRUE) | `(5 > 3) | (4 > 6)` | `TRUE`  |
| `!`      | Logical NOT (Reverses TRUE/FALSE)                | `!(5 > 3)`          | `FALSE` |


### Asking Questions with Filtering

:::note

The `filter()` function returns only the rows that meet a specified condition.

:::

From the `feel-question` column in our tidy data, these are questions asking whether social media makes students feel connected to others (`feel_), anxious or stressed, 

